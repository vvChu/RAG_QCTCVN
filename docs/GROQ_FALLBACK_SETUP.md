# Groq Fallback LLM Integration Guide

## üìã Overview

H·ªá th·ªëng RAG gi·ªù ƒë√¢y h·ªó tr·ª£ **Groq** l√†m LLM d·ª± ph√≤ng (fallback) khi Gemini API g·∫∑p s·ª± c·ªë (503 overload, rate limit, outage).

**C∆° ch·∫ø ho·∫°t ƒë·ªông:**

- **Primary**: Gemini 2.5 Flash (m·∫∑c ƒë·ªãnh)
- **Fallback**: Llama 3.3 70B (qua Groq API)
- T·ª± ƒë·ªông chuy·ªÉn ƒë·ªïi khi Gemini tr·∫£ v·ªÅ l·ªói ho·∫∑c response r·ªóng

---

## üöÄ Setup

### 1. C√†i ƒë·∫∑t Dependencies

```powershell
pip install groq
```

Ho·∫∑c update to√†n b·ªô:

```powershell
pip install -r requirements.txt
```

### 2. L·∫•y Groq API Key

1. Truy c·∫≠p: <https://console.groq.com/keys>
2. T·∫°o API key m·ªõi
3. Copy key (format: `gsk_...`)

### 3. C·∫•u h√¨nh Environment Variables

Th√™m v√†o `.env`:

```env
# Primary LLM (Gemini)
GEMINI_API_KEY=your_gemini_key_here
GEMINI_MODEL=gemini-2.5-flash

# Fallback LLM (Groq) - OPTIONAL
GROQ_API_KEY=your_groq_api_key_here
GROQ_MODEL=llama-3.3-70b-versatile
```

**L∆∞u √Ω**: N·∫øu kh√¥ng c√≥ `GROQ_API_KEY`, h·ªá th·ªëng v·∫´n ho·∫°t ƒë·ªông b√¨nh th∆∞·ªùng v·ªõi ch·ªâ Gemini.

---

## üß™ Test Fallback

Ch·∫°y script test t√≠ch h·ª£p:

```powershell
python test_groq_fallback.py
```

**Expected output:**

```
‚úÖ All tests passed! Groq fallback is ready.
```

Test bao g·ªìm:

1. Direct Groq generation (verify API connection)
2. Fallback pipeline (Gemini fail ‚Üí Groq answers)

---

## üíª Usage

### CLI Mode

```powershell
python src/main.py --mode query --question "Chi·ªÅu cao t·ªëi thi·ªÉu c·ªßa t·∫ßng 1?"
```

N·∫øu Gemini fail ‚Üí t·ª± ƒë·ªông chuy·ªÉn sang Groq.

### Python API

```python
from src.main import RAGSystem

system = RAGSystem(mode='query')
result = system.query("Kho·∫£ng c√°ch ph√≤ng ch√°y gi·ªØa 2 t√≤a nh√†?")

# Check which model answered
print(f"Primary: {result['stats']['primary_model']}")
print(f"Fallback used: {result['stats']['used_fallback']}")
print(f"Final model: {result['stats']['final_model']}")
```

---

## üìä Fallback Logic

**Trigger conditions** (t·ª± ƒë·ªông activate Groq):

1. Gemini tr·∫£ v·ªÅ exception
2. Response ch·ª©a "Error generating response"
3. Response ch·ª©a "503" ho·∫∑c "overloaded"
4. Response tr·ªëng

**Response structure:**

```json
{
  "answer": "C√¢u tr·∫£ l·ªùi...",
  "stats": {
    "primary_model": "gemini-2.5-flash",
    "fallback_model": "llama-3.3-70b-versatile",
    "used_fallback": true,
    "final_model": "llama-3.3-70b-versatile"
  }
}
```

---

## üéØ Groq Model Options

C√°c model kh·∫£ d·ª•ng tr√™n Groq (fast inference):

| Model | Best For | Speed |
|-------|----------|-------|
| `llama-3.3-70b-versatile` | General Q&A, Vietnamese | ‚ö°‚ö°‚ö° |
| `llama-3.1-70b-versatile` | Balanced performance | ‚ö°‚ö°‚ö° |
| `mixtral-8x7b-32768` | Long context (32k tokens) | ‚ö°‚ö° |
| `gemma-7b-it` | Fast, lightweight | ‚ö°‚ö°‚ö°‚ö° |

**Khuy·∫øn ngh·ªã**: `llama-3.3-70b-versatile` (default) cho vƒÉn b·∫£n ph√°p lu·∫≠t ti·∫øng Vi·ªát.

---

## ‚öôÔ∏è Advanced Configuration

### Custom Fallback Chain

```python
from src.groq_generator import GroqGenerator
from src.generator import GeminiGenerator
from src.pipeline import FallbackRAGPipeline

# Setup custom generators
primary = GeminiGenerator(api_key='...', model='gemini-2.5-flash')
fallback = GroqGenerator(api_key='...', model='mixtral-8x7b-32768')

# Custom pipeline
pipeline = FallbackRAGPipeline(
    retriever=retriever,
    primary_generator=primary,
    fallback_generator=fallback
)
```

### Force Groq Mode (Testing)

```python
# Disable Gemini temporarily
os.environ.pop('GEMINI_API_KEY', None)
# Now only Groq will work
```

---

## üìà Performance Comparison

| Model | Latency | Vietnamese Quality | Cost |
|-------|---------|-------------------|------|
| Gemini 2.5 Flash | ~2-5s | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | $ |
| Llama 3.3 70B (Groq) | ~1-3s | ‚≠ê‚≠ê‚≠ê‚≠ê | $$ |

**Trade-offs:**

- Groq: Nhanh h∆°n (~30-50% faster inference)
- Gemini: Ch·∫•t l∆∞·ª£ng ti·∫øng Vi·ªát t·ªët h∆°n m·ªôt ch√∫t

---

## üêõ Troubleshooting

### Error: "GROQ_API_KEY not found"

**Solution**: Set env variable:

```powershell
$env:GROQ_API_KEY = 'gsk_...'
```

### Fallback kh√¥ng activate

**Check:**

1. Gemini c√≥ ƒëang tr·∫£ l·ªùi b√¨nh th∆∞·ªùng?
2. Log c√≥ ch·ª©a "used_fallback: False"?
3. Th·ª≠ force fail Gemini (d√πng invalid key)

### Groq tr·∫£ v·ªÅ 429 (rate limit)

**Solution**: Groq free tier c√≥ gi·ªõi h·∫°n:

- 30 requests/minute
- Upgrade t√†i kho·∫£n ho·∫∑c th√™m delay gi·ªØa c√°c query

---

## üìù Next Steps

1. ‚úÖ Setup GROQ_API_KEY in `.env`
2. ‚úÖ Run `test_groq_fallback.py`
3. ‚úÖ Test query v·ªõi fallback
4. üìä Monitor fallback rate: `result['stats']['used_fallback']`
5. üîß Tune model n·∫øu c·∫ßn (xem Groq Model Options)

---

## üîó Resources

- **Groq Console**: <https://console.groq.com>
- **API Docs**: <https://console.groq.com/docs/quickstart>
- **Models**: <https://console.groq.com/docs/models>
- **Pricing**: <https://groq.com/pricing>

---

**Date**: 2025-11-18  
**Version**: 1.0  
**Author**: RAG System Development Team
